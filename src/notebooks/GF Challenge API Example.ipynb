{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python to Access the Geopolitical Forecasting Challenge API\n",
    "## Introduction\n",
    "\n",
    "Participation in the Geopolitical Forecasting (GF) Challenge is conducted through an API provided by Cultivate Labs. This notebook briefly demonstrates some ways to interact with the API through Python. These examples assume that you are familiar with Python 2 or 3, and have installed the [Requests](http://docs.python-requests.org/en/master/) library (which is included in distributions such as Anaconda). (NOTE: You may use these examples as part of your GF Challenge solution, but it is important to note that this code is meant primarily as a reference, and should not be assumed to be bug-free, or particularly efficient. We make no guarantees or warranties that this code will correctly retrieve or submit data to the API -- you are responsible for verifying that your forecasts are submitted correctly).\n",
    "\n",
    "Prior to participating in the GF Challenge, you must register for the GF Challenge at [HeroX](https://www.herox.com/IARPAGFChallenge), and then register on the Cultivate platform using the URLs provided. Upon registering on the Cultivate platform, you will be able to generate an API key for the staging (test) instance, and production (competition) instance of the API. This API key is unique to you, and you should ensure that it is not shared with others.  This API key is used to identify and authenticate your requests and submissions to the API.\n",
    "\n",
    "You will find complete API documentation on the Cultivate Labs site once you receive your API key. This notebook does not provide an exhaustive overview of the entire API. Instead, it is designed to highlight some key considerations for implementing a GF Challenge API client. It is not a substitute for a thorough understanding of the API documentation. This document describes some concepts related to the challenge, however, it is not an authoritative source of challenge rules. You are responsible for reviewing and understanding the official GF Challenge Rules document available on the HeroX site.\n",
    "\n",
    "All code in this document is provided using the [CC0 1.0 Universal (CC0 1.0) Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/).\n",
    "\n",
    "## General Details\n",
    "\n",
    "### Using your API Key\n",
    "\n",
    "All calls to the API must include your API key in the request headers in the following form:\n",
    "\n",
    "`headers['Authorization'] = 'Bearer ' + secret_token`\n",
    "\n",
    "So, one can submit a GET request to the API this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "secret_token = '<API_KEY>' # replace with your API token\n",
    "server = '<SERVER_NAME>'  # of the form 'https://api.[domain].com'\n",
    "url = server + '/api/v1/questions' # The endpoint to retrieve questions\n",
    "headers = {'Authorization':'Bearer ' + secret_token}\n",
    "params = {} # More to come on this in a moment\n",
    "\n",
    "result = requests.get(url, headers=headers, params=params) \n",
    "\n",
    "if result.ok:\n",
    "    j = result.json() # This will be the content you are interested in.\n",
    "else:\n",
    "    print('PROBLEM:', result.status_code, result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When POSTing forecasts, things look pretty much the same, except it would be formatted with the `.post()` method, and the parameters would be submitted as `json`:\n",
    "\n",
    "`result = requests.post(url, headers=headers, json=params)`\n",
    "\n",
    "### Passing parameters to the API\n",
    "\n",
    "Typically, you'll want to provide specific parameters when making your API calls, (e.g., asking for human forecasts made against a specific forecasting question, requesting information that has been updated since you last checked).  To do that, you will pass a set of parameters in python dictionary form.  The dictionary structure will be identical to the examples provided in the Cultivate API documentation.\n",
    "\n",
    "As an example, you may want to receive all human forecasts made against question number 5 since March 10, 2018. You would set your params dictionary as:\n",
    "\n",
    "`params = {'question_id':5, 'created_after':'2018-03-10T00:00:00.000Z'}`\n",
    "\n",
    "The full set of required and optional input parameters are listed in the Cultivate API documentation.\n",
    "\n",
    "### Recieving Responses\n",
    "\n",
    "When a GET or POST request is successfully executed, you will receive a JSON formatted response which can be accessed as the response's `.json()` object.\n",
    "\n",
    "#### Paging\n",
    "\n",
    "All paginated endpoints will also include 2 pagination-related response headers: `X-Total-Page-Count` and `X-Total-Record-Count`. `X-Total-Page-Count` contains the total number of pages available for your request, while `X-Total-Record-Count` contains the total number of records that will be included across all of those pages.\n",
    "\n",
    "You can access these through the response's `headers` dictionary:\n",
    "\n",
    "```\n",
    "result = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if result.ok:\n",
    "    totalPages = int(resp.headers.get('X-Total-Page-Count',0))\n",
    "```\n",
    "\n",
    "By default, results are returned for the first page (page 0), updating the `params` dictionary to include `params['page'] = 1` would get the next page.\n",
    "\n",
    "## Primary API Endpoints\n",
    "\n",
    "### Retrieving Questions\n",
    "\n",
    "Individual Forecasting Problems (IFPs) are questions about future events that solvers forecast against, and can be retrieved from the `questions` API endpoint. Each IFP includes, among other fields, an `id` a `description`, a set of `answers`, and a collection of `metadata` as well as starting and ending dates. Questions can be retrieved using a GET request, optionally specifying the `status` (active, closed, all) or limiting the dates questions were updated or created. The `answers` are a list of mutually exclusive, and collectively exhaustive options describing possible IFP outcomes. Forecasts must specify probabilities for each possible outcome that sum to 1.0 (except for binary questions (e.g., yes/no) for which only one option is presented, with the other option being calculated as 1 - Option A).\n",
    "\n",
    "The `metadata` that is returned includes `Domain`, `Topic`, and location information. These fields come into play in the interim prizes and the Domain/Region pair prizes.  Refer to the GF Challenge Rules document and the API documentation to ensure that you accurately retrieve and handle the relevant fields. \n",
    "\n",
    "Each IFP also includes a list of `clarifications`. This will be populated if there is additional guidance regarding the IFP issued. This can include situations where terms are further defined, or sources of resolution are changed. You should regularly check for updates to this field.\n",
    "\n",
    "### Retrieving Human Forecasts\n",
    "\n",
    "As part of the GF Challenge, solvers will have access to forecasts made by a crowd of human forecasters. These forecasts will be made available in two forms: individual and aggregate.  The individual forecasts are made available through the `prediction_sets` API end point, while the aggregate forecasts are provided through the `consensus_histories` end point. The consensus is calculated using an aggregation algorithm called logit. The logit aggregation method is an extremizing method that uses a weighted geometric mean to aggregate forecasts. Forecaster weights are calculated based on 3 factors: historical accuracy, the frequency with which the forecaster updates his or her forecasts, and whether the forecaster completed a training course. The `consensus_histories` data also serve as the baseline against which Solvers will be compared. More details on the baseline and scoring can be found in the official GF Challenge Rules.\n",
    "\n",
    "Individual forecasts contain the probability forecasts, including a `question_id` that maps to the `id` in from the `questions` endpoint and `membership_guid` which uniquely identifies the human forecaster. Each forecast will include a list of `predictions` reflecting the probabilities that person assigned to each possible answer. The `forecasted_probability` for each answer represents that person's beliefs for each answer.\n",
    "\n",
    "Consensus aggregations contain a `question_id` and `answer_id` pair that identify a particular answer option. The `normalized_value` for a particular answer reflects the score such that all answers to a particular question will sum to 1.0. This consensus is updated any time a human forecaster makes a new forecast against an IFP. The `consensus_histories` API end point contains a list of these updated consensus scores. The most recent consensus for a particular question reflects the current crowd consensus at that time. NOTE: With the exception of the first time you query this endpoint, you should NOT retrieve `consensus_histories` without specifying a `created_after` parameter.  \n",
    "\n",
    "### Submitting Forecasts\n",
    "\n",
    "Forecast submission is done through an HTTP POST. Your forecast must include the `question_id`, an `external_predictor_attributes.method_name`, and `external_predictions_attributes`: a list of dictionaries each containing an `answer_id` and `value` for each of the forecast question's possible alternatives. The sum of the values must equal 1.0. \n",
    "\n",
    "Each GF Challenge solver is allocated 25 methodological \"slots.\" These slots can be used to represent different strategies for weighting data sources, different algorithms, etc. The `method_name` parameter is used to identify which slot a forecast should be associated with. `method_name` can be up to 50 characters, and will be held constant throughout the challenge (i.e., you cannot add a 26th method). You will be scored on a per `method_name` basis, with only your best performing approach being considered for each prize category. For more details, review the GF Challenge rules.\n",
    "\n",
    "A forecast submission can look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"external_prediction_set\": {\n",
    "        \"question_id\": 123,\n",
    "        \"external_predictor_attributes\": {\n",
    "            \"method_name\": \"red\"\n",
    "            },\n",
    "        \"external_predictions_attributes\": [\n",
    "            {\"value\": 0.6, \"answer_id\": 431},\n",
    "            {\"value\": 0.35, \"answer_id\": 432},\n",
    "            {\"value\": 0.05, \"answer_id\": 433}\n",
    "            ]\n",
    "          }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful submission of a forecast to the submission endpoint will return a json summary of the submission, including the time of submission. A failure (e.g., incorrect `answer_id` or `value`s that don't total to 1.0, or attempting to create a 26th `method_name`) will result in json describing the error. It is advisable to inspect the resulting json to ensure it reflects the intended forecast.\n",
    "\n",
    "## Putting it All Together\n",
    "\n",
    "We can implement API access into a single Python class so we can make GET and POST requests in a consistent fashion.  Below, we define a `GfcApi` class that allows us to specify a server and API token one time and access all the API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from pprint import pprint #This is just to make things look pretty...\n",
    "\n",
    "#Make this python 2 and 3 compliant\n",
    "from __future__ import print_function\n",
    "\n",
    "class GfcApi(object):\n",
    "    \"\"\"\n",
    "        An example class for interacting with the IARPA Geopolitical Forecasting Challenge\n",
    "        API.  Note that this code is for reference purposes, no warranties are expressed\n",
    "        or implied.  \n",
    "    \"\"\"\n",
    "    def __init__(self,token,server,proxy=None,verbose=False):\n",
    "        \"\"\"\n",
    "            Create an instance of an API client. This assumes you have an OAuth token.\n",
    "            \n",
    "            Arguments\n",
    "            \n",
    "            REQUIRED\n",
    "            token - <string> - The secret API token assigned when registering on the \n",
    "                               Cultivate platform\n",
    "            \n",
    "            server - <string> - The beginning of the server url in the form:\n",
    "                                https://api.XXXXXXX.com.  This is described in the\n",
    "                                Cultivate API documentation\n",
    "            \n",
    "            OPTIONAL\n",
    "            proxy - <dictionary> - If you are behind a proxy server, you can specify the details\n",
    "                                   in the form: \n",
    "                                       proxy = {'http': http_proxy,\n",
    "                                                'https': https_proxy,\n",
    "                                                'ftp': ftp_proxy}\n",
    "                                   where an individual entry might be [ip address:port]. See the\n",
    "                                   requests library documentation for more details.\n",
    "                Default: None\n",
    "                \n",
    "            verbose - <boolean> - If true, we print GET and POST request URLs and params\n",
    "                Default: False\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.token = token\n",
    "        self.server = server\n",
    "        self.proxy = proxy\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.sess = requests.session()\n",
    "        self.rate_limit_delay = 1 #seconds between subsequent API calls\n",
    "        self.last_call_time = 0.0 \n",
    "        self.set_urls()\n",
    "    \n",
    "    def set_urls(self):\n",
    "        if not self.server.endswith('/'):\n",
    "            self.server += '/'\n",
    "    \n",
    "        self.api_base = self.server + 'api/v1/'\n",
    "    \n",
    "        self.consensus_histories_url = self.server + 'aggregation/api/v1/control/consensus_histories'\n",
    "        self.external_prediction_sets_url = self.api_base + 'external_prediction_sets'\n",
    "        self.prediction_sets_url = self.api_base + 'control/prediction_sets'\n",
    "        self.questions_url = self.api_base + 'questions'\n",
    "\n",
    "    def get_questions(self, status=None, created_before=None, created_after=None,\n",
    "                  sort='published_at', updated_before=None, updated_after=None):\n",
    "        \"\"\"\n",
    "            This function retrieves Individual Forecasting Problems (IFPs).\n",
    "\n",
    "            Optional Inputs:\n",
    "            status - <string> - IFP status\n",
    "                    Possible Values:\n",
    "                        'active' - only return questions that are currently open for forecasting\n",
    "                        'closed' - return all resolved or otherwised closed questions\n",
    "                        'all'    - return all active and closed questions\n",
    "                    Default Value:\n",
    "                        'active'\n",
    "\n",
    "            created_before - <datetime> - returns only questions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only questions created after this time\n",
    "            \n",
    "            sort - <string> - Sort order of returned questions\n",
    "                    Possible Values:\n",
    "                        'published_at'\n",
    "                        'ends_at'\n",
    "                        'resolved_at'\n",
    "                        'prediction_sets_count'\n",
    "                    Default Value:\n",
    "                        'published_at'\n",
    "            \n",
    "            updated_before - <datetime> - returns only questions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only questions updated after this time\n",
    "                    \n",
    "             Output:\n",
    "            JSON representation of a list of Individual Forecasting Problems\n",
    "        \"\"\"\n",
    "        \n",
    "        url = self.questions_url\n",
    "        section = 'questions'\n",
    "        params={}\n",
    "        \n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if created_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if created_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        if status:\n",
    "            params['status'] = status\n",
    "        if sort:\n",
    "            params['sort'] = sort  \n",
    "        \n",
    "        return self._get_pages(url=url,section=section,params=params)\n",
    "    \n",
    "    def get_human_forecasts(self, question_id=None, created_before=None, created_after=None,\n",
    "                           updated_before=None, updated_after=None):\n",
    "\n",
    "        \"\"\"\n",
    "            This function retrieves the stream of human forecasts against IFPs.\n",
    "\n",
    "            Optional Inputs:\n",
    "            question_id - <integer> - returns predictions for a single question\n",
    "                    Default Value:\n",
    "                        None\n",
    "\n",
    "            created_before - <datetime> - returns only predictions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only predictions created after this time\n",
    "            \n",
    "            updated_before - <datetime> - returns only predictions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only predictions updated after this time\n",
    "                    \n",
    "             Output:\n",
    "            JSON representation of a list of human forecasts\n",
    "        \"\"\"\n",
    "        \n",
    "        url = self.prediction_sets_url\n",
    "        section = 'prediction_sets'\n",
    "        params={}\n",
    "        \n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if updated_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if updated_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        if question_id:\n",
    "            params['question_id'] = question_id\n",
    "        \n",
    "        return self._get_pages(url=url,section=section,params=params)        \n",
    "    \n",
    "    def get_consensus_histories(self, question_id=None, created_before=None, created_after=None,\n",
    "                           updated_before=None, updated_after=None):\n",
    "\n",
    "        \"\"\"\n",
    "            This function retrieves the consensus of human forecasts against IFPs.\n",
    "\n",
    "            NOTE: You need to include some date constraints after your first use of this API. \n",
    "            Always utilize the created_after parameter to pull only those records that have \n",
    "            been created since you last accessed the API. Do not attempt to pull every \n",
    "            record/page of the history.\n",
    "\n",
    "            Optional Inputs:\n",
    "            \n",
    "            question_id - <integer> - returns only predictions made about a specific IFP\n",
    "                Default Value\n",
    "                    None\n",
    "\n",
    "            created_before - <datetime> - returns only predictions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only predictions created after this time\n",
    "            \n",
    "            updated_before - <datetime> - returns only predictions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only predictions updated after this time\n",
    "                    \n",
    "             Output:\n",
    "            JSON representation of a list of human forecasts\n",
    "        \"\"\"\n",
    "        \n",
    "        if (not created_before) and (not created_after) and (not updated_before) and (not updated_after):\n",
    "            print(\"After your first query, use a date constraint (created_before/after or\",\\\n",
    "                  \"updated_before/after) to get consensus history. Old values won't change\")\n",
    "        \n",
    "        url = self.consensus_histories_url\n",
    "        section = 'consensus_histories'\n",
    "        params={}\n",
    "        \n",
    "        if question_id:\n",
    "            params['question_id'] = str(question_id)\n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if updated_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if updated_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        \n",
    "        return self._get_pages(url=url,section=section,params=params)   \n",
    "    \n",
    "    def submit_forecast(self,question_id,method_name,predictions):\n",
    "        \"\"\"\n",
    "            Submit probabilistic forecasts against a question.\n",
    "            \n",
    "            Required Parameters\n",
    "            \n",
    "            question_id - <integer> - The question_id of the IFP being forecast against\n",
    "            \n",
    "            method_name - <string> - The name of one of your 25 forecasting methods. Up to 50 chars\n",
    "                             NOTE: This is used to track and score your forecasting methods. You\n",
    "                             are responsible for keeping track of your named methods. Using a new\n",
    "                             method_name will automatically add a new method - unless you have\n",
    "                             already created 25 methods. In that case, you'll get an error message\n",
    "                             in the response.\n",
    "                             \n",
    "            predictions - <list> - A list of Dictionaries in the form .\n",
    "                                                   {'answer_id': <Integer>, 'value': <Decimal>}\n",
    "                            \n",
    "                          If the question is binary (exactly two possible answers), you only submit a\n",
    "                          prediction for one possible answer, with the other being equal to 1 minus\n",
    "                          your prediction for option A.\n",
    "                          \n",
    "                          NOTE: The set of values in the forecast must equal exactly 1.0 or you will \n",
    "                          receive an error message in the response.\n",
    "            \n",
    "     RESPONSE\n",
    "     The json response will either summarize your forecast to this question, or it will contain an \n",
    "     error message indicating why it wasn't accepted.  You are responsible for recieving and reviewing\n",
    "     the response to ensure that your forecast was accepted, and reflects your intentions.  You can \n",
    "     resubmit forecasts to a particular IFP repeatedly over the course of a forecast day, and each\n",
    "     new submission will replace older submissions for scoring purposes. Review the GF Challenge\n",
    "     Rules for details on forecast submission and scoring.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = self.external_prediction_sets_url\n",
    "        \n",
    "        params={'external_prediction_set':{'question_id':question_id,\n",
    "                                          'external_predictor_attributes':\n",
    "                                           {'method_name':method_name},\n",
    "                                           'external_predictions_attributes':predictions}\n",
    "                }\n",
    "        \n",
    "        return self._post(url,params)\n",
    "    \n",
    "    def _forecast_template(self,ifp):\n",
    "        \"\"\"\n",
    "            A tiny little helper function to create the basis for the predictions parameter in\n",
    "            the submit_forecast function.  You pass an IFP from the questions API into this \n",
    "            function and receive a list of 'answer_id' and 'value' dictionaries that are\n",
    "            needed to submit a forecast.  \n",
    "            \n",
    "            NOTE: This uses the existing 'probability' value from the questions API which should be\n",
    "            replaced with your own forecast values.\n",
    "        \"\"\"\n",
    "        \n",
    "        output = [{'answer_id':a['id'],'value':a['probability']} for a in ifp['answers']]\n",
    "        return output\n",
    "    \n",
    "    def _get_pages(self,url,params,section):\n",
    "        \n",
    "        \"\"\"\n",
    "            This function uses _get to make authenticated calls to the\n",
    "            relevant API endpoints with the user-provided parameters.\n",
    "            \n",
    "            This function handles paging through results, and returns only the list from\n",
    "            the resulting json result(s).\n",
    "            \n",
    "            The 'url' and 'params' describe the API query, the 'section' is the key in the\n",
    "            returned json that contains the list of query results (e.g., 'questions').\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print('Get Pages for {}'.format(url))\n",
    "            print(params)\n",
    "        page = 0\n",
    "        maxPage = 1\n",
    "        \n",
    "        all_results = []\n",
    "        this_batch = []\n",
    "        while page < maxPage: \n",
    "            \n",
    "            params['page']=page\n",
    "            resp = self._get(url=url,params=params)\n",
    "            maxPage = int(resp.headers.get('X-Total-Page-Count',0))\n",
    "            try:\n",
    "                results=resp.json()\n",
    "            except:\n",
    "                results=None\n",
    "            if isinstance(results,(list,dict)):\n",
    "                if 'errors' in results:\n",
    "                    print(results['errors'])\n",
    "                    return results\n",
    "                \n",
    "                this_batch = results[section]\n",
    "                all_results.extend(this_batch)\n",
    "\n",
    "                page+=1\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"PROBLEM\")\n",
    "                return results\n",
    "\n",
    "        return all_results                \n",
    "        \n",
    "    def _get(self,url,params):\n",
    "        \"\"\"\n",
    "            A helper function that handles authentication and rate limiting.\n",
    "            \n",
    "            Given a URL and a set of parameters, this function calls the Cultivate API\n",
    "            and returns the json response.\n",
    "        \"\"\"\n",
    "        \n",
    "        while time.time() < self.last_call_time + self.rate_limit_delay:\n",
    "            if self.verbose:\n",
    "                print(\"{}: Sleeping\".format(time.ctime()))\n",
    "            time.sleep(1)\n",
    "        \n",
    "        headers={'Authorization':'Bearer ' + self.token} #This is needed to authenticate\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"{}: GETTING {}\".format(time.ctime(),url))\n",
    "            safeHeaders = {k:v for k,v in headers.items() if k!='Authorization'}\n",
    "            safeHeaders['Authorization']=\"Bearer <shhhhhh it's a secret>\"\n",
    "            print(\"\\tHeaders: {}\".format(safeHeaders))\n",
    "            print(\"\\tArgs: {}\".format(params))\n",
    "        resp = self.sess.get(url, headers=headers, params=params, proxies=self.proxy)\n",
    "                                                                                         \n",
    "        self.last_call_time = time.time()\n",
    "        return resp\n",
    "    \n",
    "    def _post(self,url,params):\n",
    "        \"\"\"\n",
    "            A helper function that handles authentication.\n",
    "            \n",
    "            Given a URL and a set of parameters, this function submits a POST to the \n",
    "            Cultivate API and returns the json response.\n",
    "            \n",
    "            Output\n",
    "            JSON response describing the forecast or indicating an error.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        while time.time() < self.last_call_time + self.rate_limit_delay:\n",
    "            if self.verbose:\n",
    "                print(\"{}: Sleeping\".format(time.ctime()))\n",
    "            time.sleep(1)\n",
    "        \n",
    "        headers={'Authorization':'Bearer ' + self.token} #This is needed to authenticate\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"{}: POSTING {}\".format(time.ctime(),url))\n",
    "            safeHeaders = {k:v for k,v in headers.items() if k!='Authorization'}\n",
    "            safeHeaders['Authorization']=\"Bearer <shhhhhh it's a secret>\"\n",
    "            print(\"\\tHeaders: {}\".format(safeHeaders))\n",
    "            print(\"\\tArgs: {}\".format(params))\n",
    "        resp = self.sess.post(url, headers=headers, json=params, proxies=self.proxy) \n",
    "                                                                                         \n",
    "        self.last_call_time = time.time()\n",
    "        \n",
    "        return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can invoke this class by specifying our secret_token and server.\n",
    "\n",
    "One strategy for token management is to create a dictionary of server instances with the server address and API token like:\n",
    "\n",
    "```\n",
    "secrets = {'staging':{'key':'<API KEY>','server':'https://api.<STAGING DOMAIN>.com'},\n",
    "          'production':{'key':'<API KEY>','server':'https://api.<PRODUCTION DOMAIN>.com'}}\n",
    "```\n",
    "We can create an instance of the `GfcApi` class thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance='staging'\n",
    "gf=GfcApi(secrets[instance]['key'],secrets[instance]['server'],verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we create an instance of the `GfcApi` class, we retrieve Individual Forecasting Problems (IFPs). We could limit our queries of IFPs based on date of creation or update (useful for finding clarifications).  We can also limit our query to active (or closed) questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've downloaded 4 IFPs\n",
      "\n",
      "IFP 325: Single Answer question test\n",
      "Description: \n",
      "Starts: 2018-02-15T14:57:00.000Z, Ends: 2018-03-15T14:57:00.000Z\n",
      "Options:\n",
      " (685) Ice\n",
      "\n",
      "IFP 256: test ordinal question\n",
      "Description: this is a description\n",
      "Starts: 2018-02-10T19:01:01.000Z, Ends: 2018-03-10T19:01:01.000Z\n",
      "Options:\n",
      " (511) answer a\n",
      " (512) answer b\n",
      " (513) answer c\n",
      "\n",
      "IFP 211: test binary question\n",
      "Description: \n",
      "Starts: 2018-01-21T18:55:38.000Z, Ends: 2018-06-01T17:55:38.000Z\n",
      "Options:\n",
      " (446) Yes\n",
      "\n",
      "IFP 221: test multinomial\n",
      "Description: \n",
      "Starts: 2018-02-05T16:45:01.000Z, Ends: 2018-08-04T15:44:34.000Z\n",
      "Options:\n",
      " (456) A\n",
      " (457) B\n",
      " (458) C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifps=gf.get_questions()\n",
    "print(\"We've downloaded {} IFPs\\n\".format(len(ifps)))\n",
    "\n",
    "for ifp in ifps:\n",
    "    print(\"IFP {}: {}\".format(ifp['id'],ifp['name']))\n",
    "    print(\"Description: {}\".format(ifp['description']))\n",
    "    print(\"Starts: {}, Ends: {}\".format(ifp['starts_at'],ifp['ends_at']))\n",
    "    print(\"Options:\")\n",
    "    for answer in ifp['answers']:\n",
    "        print(' ({}) {}'.format(answer['id'],answer['name']))\n",
    "        \n",
    "    if ifp['clarifications']:\n",
    "        print('Clarifications:')\n",
    "        print(ifp['clarifications'])\n",
    "    print(\"\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve human forecasts. If we'd like, we can limit them to a particular `question_id`, and can constrain the creation or update dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 human forecasts\n"
     ]
    }
   ],
   "source": [
    "preds=gf.get_human_forecasts()\n",
    "if 'errors' in preds:\n",
    "    print(\"We ran into a problem:\")\n",
    "    print(preds)\n",
    "else:\n",
    "    print(\"Retrieved {} human forecasts\".format(len(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an item in the human forecast stream. The `question_id` links us to the `get_questions()` results. the `membership_guid` is the unique identifier for a human forecaster, and will remain consistent throughout the GF Challenge.\n",
    "\n",
    "Each item in the `predictions` list includes the `answer_id` for that alternative, which aligns to the `get_questions()` output, and a `forecasted_probability` which indicates the human forecaster's submitted probability for that alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_id': 15,\n",
       " 'created_at': '2018-02-15T19:44:14.707Z',\n",
       " 'discover_question_id': 40,\n",
       " 'id': 4,\n",
       " 'membership_guid': 'cc4c30df5539f534690f0a36209738ce78a04180',\n",
       " 'predictions': [{'answer_id': 685,\n",
       "   'answer_name': 'Ice',\n",
       "   'confidence_level': None,\n",
       "   'created_at': '2018-02-15T19:44:14.724Z',\n",
       "   'filled_at': '2018-02-15T19:44:14.724Z',\n",
       "   'final_probability': 0.15,\n",
       "   'forecasted_probability': 0.15,\n",
       "   'id': 10,\n",
       "   'made_after_correctness_known': False,\n",
       "   'membership_guid': 'cc4c30df5539f534690f0a36209738ce78a04180',\n",
       "   'refunded_at': None,\n",
       "   'starting_probability': 0.5,\n",
       "   'type': 'Forecast::Prediction',\n",
       "   'updated_at': '2018-02-15T21:45:08.420Z'}],\n",
       " 'question_id': 325,\n",
       " 'question_name': 'Single Answer question test',\n",
       " 'rationale': 'test rationale',\n",
       " 'type': 'Forecast::OpinionPoolPredictionSet',\n",
       " 'updated_at': '2018-02-15T21:45:08.413Z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the baseline consensus forecasts using `get_consensus_histories()`. As described in the API documentation, and above, after your first call to this API endpoint, you should constrain your requests using something like `created_after` while storing tracking older values locally. Note that we're using `datetime.datetime()` objects to specify the `created` and `updated` parameters. You can limit this request by `question_id` if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved 9 consensus scores\n"
     ]
    }
   ],
   "source": [
    "cons = gf.get_consensus_histories(created_after=datetime.datetime(2018,1,1,0,0,0),\n",
    "                                  updated_before=datetime.datetime(2018,2,11)) \n",
    "print(\"retrieved {} consensus scores\".format(len(cons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these results. Note that each item in the list represents a single answer -- unlike an item in the `get_human_forecasts()` results where each entry represents the predictions for each possible answer for a single IFP.\n",
    "\n",
    "The `normalized_value` scores for all the answers to a single IFP for a specific `consensus_at` time will add up to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_id': 511,\n",
       "  'consensus_at': '2018-02-10T23:06:52.065Z',\n",
       "  'created_at': '2018-02-10T23:06:52.674Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 15,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.45000005,\n",
       "  'prediction_set_id': 3,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T23:06:52.674Z',\n",
       "  'value': 1.0,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 512,\n",
       "  'consensus_at': '2018-02-10T23:06:52.065Z',\n",
       "  'created_at': '2018-02-10T23:06:52.650Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 16,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.14999986,\n",
       "  'prediction_set_id': 3,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T23:06:52.650Z',\n",
       "  'value': 0.333333,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 513,\n",
       "  'consensus_at': '2018-02-10T23:06:52.065Z',\n",
       "  'created_at': '2018-02-10T23:06:52.626Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 17,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.40000009,\n",
       "  'prediction_set_id': 3,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T23:06:52.626Z',\n",
       "  'value': 0.888889,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 511,\n",
       "  'consensus_at': '2018-02-10T19:25:19.090Z',\n",
       "  'created_at': '2018-02-10T19:25:20.699Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 9,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.24000004,\n",
       "  'prediction_set_id': 1,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.870Z',\n",
       "  'value': 1.0,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 512,\n",
       "  'consensus_at': '2018-02-10T19:25:19.090Z',\n",
       "  'created_at': '2018-02-10T19:25:20.559Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 10,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.65000002,\n",
       "  'prediction_set_id': 1,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.891Z',\n",
       "  'value': 2.708333,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 513,\n",
       "  'consensus_at': '2018-02-10T19:25:19.090Z',\n",
       "  'created_at': '2018-02-10T19:25:20.449Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 11,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.10999994,\n",
       "  'prediction_set_id': 1,\n",
       "  'question_id': 256,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.911Z',\n",
       "  'value': 0.458333,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 456,\n",
       "  'consensus_at': '2018-02-10T19:21:06.516Z',\n",
       "  'created_at': '2018-02-10T19:21:08.106Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 12,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.25,\n",
       "  'prediction_set_id': 2,\n",
       "  'question_id': 221,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.937Z',\n",
       "  'value': 1.0,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 457,\n",
       "  'consensus_at': '2018-02-10T19:21:06.516Z',\n",
       "  'created_at': '2018-02-10T19:21:08.075Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 13,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.65,\n",
       "  'prediction_set_id': 2,\n",
       "  'question_id': 221,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.956Z',\n",
       "  'value': 2.6,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}},\n",
       " {'answer_id': 458,\n",
       "  'consensus_at': '2018-02-10T19:21:06.516Z',\n",
       "  'created_at': '2018-02-10T19:21:08.046Z',\n",
       "  'decay_args': {'percent': 0.468},\n",
       "  'decay_method': 'Aggregation::Decay::PercentRecent',\n",
       "  'id': 14,\n",
       "  'method_name': '1-WeightedLogit-PercentRecent',\n",
       "  'normalized_value': 0.1,\n",
       "  'prediction_set_id': 2,\n",
       "  'question_id': 221,\n",
       "  'strategy': 'Aggregation::Strategies::Logit',\n",
       "  'updated_at': '2018-02-10T21:30:09.975Z',\n",
       "  'value': 0.4,\n",
       "  'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
       "   'enabled': True,\n",
       "   'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
       "   'percentage_of_closed_questions_answered_requirement': 0.5}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and submitting a forecast\n",
    "---\n",
    "\n",
    "The `submit_forecast()` function is used to submit probabilistic forecasts against IFPs.  Each forecast must include the `question_id`, a `method_name`, and `predictions`, a list of question_id and value dictionaries that reflect your beliefs about how the IFP will resolve. The sum of all the values must equal 1.0, unless the IFP is a binary question (having only two possible outcomes), in which case, only the forecast for Option A is submitted, with Option B being inferred to be 1 minus the value of Option A.\n",
    "\n",
    "We can make this process a bit easier by taking advantage of the `_forecast_template()` function to create a starting list of forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting IFP 256, using the \"Roll a d20\" method:\n",
      "[{'value': 0.5, 'answer_id': 511}, {'value': 0.1, 'answer_id': 512}, {'value': 0.4, 'answer_id': 513}]\n",
      "\n",
      "\n",
      "{'created_at': '2018-02-22T20:30:30.643Z',\n",
      " 'discover_question_id': 39,\n",
      " 'external_predictions': [{'answer_id': 511,\n",
      "                           'created_at': '2018-02-22T20:30:30.653Z',\n",
      "                           'discover_answer_id': 78,\n",
      "                           'forecast_at': '2018-02-22T20:30:30Z',\n",
      "                           'id': 108,\n",
      "                           'membership_id': 26,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 256,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2018-02-22T20:30:30.653Z',\n",
      "                           'value': 0.5},\n",
      "                          {'answer_id': 512,\n",
      "                           'created_at': '2018-02-22T20:30:30.658Z',\n",
      "                           'discover_answer_id': 79,\n",
      "                           'forecast_at': '2018-02-22T20:30:30Z',\n",
      "                           'id': 109,\n",
      "                           'membership_id': 26,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 256,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2018-02-22T20:30:30.658Z',\n",
      "                           'value': 0.1},\n",
      "                          {'answer_id': 513,\n",
      "                           'created_at': '2018-02-22T20:30:30.667Z',\n",
      "                           'discover_answer_id': 80,\n",
      "                           'forecast_at': '2018-02-22T20:30:30Z',\n",
      "                           'id': 110,\n",
      "                           'membership_id': 26,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 256,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2018-02-22T20:30:30.667Z',\n",
      "                           'value': 0.4}],\n",
      " 'forecast_at': '2018-02-22T20:30:30Z',\n",
      " 'id': 52,\n",
      " 'membership_id': 26,\n",
      " 'metadata': None,\n",
      " 'method_name': 'Roll a d20',\n",
      " 'method_type': 'official',\n",
      " 'question_id': 256,\n",
      " 'site_id': 2,\n",
      " 'updated_at': '2018-02-22T20:30:30.643Z'}\n"
     ]
    }
   ],
   "source": [
    "myIFP = ifps[1]\n",
    "id=myIFP['id']\n",
    "\n",
    "method=\"Roll a d20\"\n",
    "\n",
    "forecasts = gf._forecast_template(myIFP)\n",
    "\n",
    "forecasts[0]['value'] = 0.5  #Set our probability for this option\n",
    "forecasts[1]['value'] = 0.1\n",
    "forecasts[2]['value'] = .4\n",
    "\n",
    "print('Forecasting IFP {}, using the \"{}\" method:'.format(id,method))\n",
    "print(forecasts)\n",
    "\n",
    "result = gf.submit_forecast(id,method,forecasts)\n",
    "print(\"\\n\")\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what happens when your answers sum to something other than 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting IFP 256, using the \"Roll a d20\" method:\n",
      "[{'value': 0.6, 'answer_id': 511}, {'value': 0.1, 'answer_id': 512}, {'value': 0.4, 'answer_id': 513}]\n",
      "\n",
      "\n",
      "{'errors': {'predictions': ['must add up to 100%']}}\n"
     ]
    }
   ],
   "source": [
    "myIFP = ifps[1]\n",
    "id=myIFP['id']\n",
    "\n",
    "method=\"Roll a d20\"\n",
    "\n",
    "forecasts = gf._forecast_template(myIFP)\n",
    "\n",
    "forecasts[0]['value'] = 0.6  #This is different than the previous entry, and will push our total to 1.1\n",
    "forecasts[1]['value'] = 0.1\n",
    "forecasts[2]['value'] = .4\n",
    "\n",
    "print('Forecasting IFP {}, using the \"{}\" method:'.format(id,method))\n",
    "print(forecasts)\n",
    "\n",
    "result = gf.submit_forecast(id,method,forecasts)\n",
    "print(\"\\n\")\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Closing Thoughts\n",
    "Your solution to the GF challenge will need to interact, at the very least with the `questions` and `external_prediction_sets` end points. You will need to make authenticated calls to GET and POST to these end points. You may use any of the concepts or code in this document to help you accomplish these tasks, but please note that you are responsible for ensuring that you are correctly retrieving and submitting information to the API.\n",
    "\n",
    "Note that you should be on the lookout for errors that are returned either because of connectivity issues (Requests library) or as returned json content from the Cultivate API.  The examples in this document don't include comprehensive error checking or handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
