{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python to Access the Geopolitical Forecasting Challenge 2 API\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Participation in Geopolitical Forecasting (GF) Challenge 2 is conducted through an API provided by Cultivate Labs. This notebook briefly demonstrates some ways to interact with the API through Python. These examples assume that you are familiar with Python 2 or 3, and have installed the [Requests](http://docs.python-requests.org/en/master/) library (which is included in distributions such as Anaconda). (NOTE: You may use these examples as part of your Challenge solution, but it is important to note that this code is meant primarily as a reference, and should not be assumed to be bug-free, or particularly efficient. We make no guarantees or warranties that this code will correctly retrieve or submit data to the API -- you are responsible for verifying that your forecasts are submitted correctly).\n",
    "\n",
    "Prior to participating in GF Challenge 2, you must register at [HeroX](https://www.herox.com/IARPAGFChallenge2), and then register on the Cultivate platform using the URLs provided. Upon registering on the Cultivate platform, you will be able to generate an API key for the staging (test) instance, and production (competition) instance of the API. This API key is unique to you, and you should ensure that it is not shared with others.  This API key is used to identify and authenticate your requests and submissions to the API.  (*Note that API keys from the first GF Challenge have been deactivated; you will need a new key to participate in GF Challenge 2*.)\n",
    "\n",
    "You will find complete [API documentation on the Cultivate Labs site](https://cultivate-hfc.github.io/gfc-api-docs/) once you receive your API key. This notebook does not provide an exhaustive overview of the entire API. Instead, it is designed to highlight some key considerations for implementing a GF Challenge 2 API client. It is not a substitute for a thorough understanding of the API documentation. This document describes some concepts related to the challenge, however, it is not an authoritative source of challenge rules. You are responsible for reviewing and understanding the official GF Challenge 2 Rules document available on the HeroX site.\n",
    "\n",
    "All code in this document is provided using the [CC0 1.0 Universal (CC0 1.0) Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/).\n",
    "\n",
    "## General Details\n",
    "\n",
    "There are two separate but similar APIs for GF Challenge 2 on the Cultivate Labs platform.  The **Staging** platform (URL https://api.gfc-staging.com) is provided for Solvers to get familiar with the procedures for accessing the data and submitting forecasts in a practice mode.  The **Production** platform (URL https://api.iarpagfchallenge.com) is the platform for the competition.  The two platforms use separate API keys.  It is recommended that you use the Staging platform as you work through the code examples in this notebook.\n",
    "\n",
    "### Using your API Key\n",
    "\n",
    "All calls to the API must include your API key in the request headers in the following form:\n",
    "\n",
    "`headers['Authorization'] = 'Bearer ' + secret_token`\n",
    "\n",
    "So, one can submit a GET request to the API this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_STAGING_SECRET = \"MY STAGING API KEY\" # Insert your API token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We retrieved 5 IFPs\n"
     ]
    }
   ],
   "source": [
    "STAGING_URL = \"https://api.gfc-staging.com\"\n",
    "\n",
    "import requests\n",
    "\n",
    "secret_token = MY_STAGING_SECRET\n",
    "server = STAGING_URL\n",
    "url = server + '/api/v1/questions' # The endpoint to retrieve questions\n",
    "headers = {'Authorization':'Bearer ' + secret_token}\n",
    "params = {} # More to come on this in a moment\n",
    "\n",
    "result = requests.get(url, headers=headers, params=params) \n",
    "\n",
    "if result.ok:\n",
    "    j = result.json() # This will be the content you are interested in.\n",
    "    ifp_count = len(j[\"questions\"])\n",
    "    print(\"We retrieved {} IFPs\".format(ifp_count))\n",
    "else:\n",
    "    print('PROBLEM:', result.status_code, result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your request is successful the variable `j` will hold a Python dict of the form {\"questions\": List of dicts} where each dict will contain the data for a single IFP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When POSTing forecasts, things look pretty much the same, except it would be formatted with the `.post()` method, and the parameters would be submitted as `json`:\n",
    "\n",
    "`result = requests.post(url, headers=headers, json=params)`\n",
    "\n",
    "### Passing parameters to the API\n",
    "\n",
    "Typically, you'll want to provide specific parameters when making your API calls, (e.g., asking for human forecasts made against a specific forecasting question, requesting information that has been updated since you last checked).  To do that, you will pass a set of parameters in python dictionary form.  The dictionary structure will be identical to the examples provided in the Cultivate API documentation.\n",
    "\n",
    "As an example, you may want to receive all human forecasts made against question number 5 since May 20, 2019. You would set your params dictionary as:\n",
    "\n",
    "`params = {'question_id':5, 'created_after':'2019-05-20T00:00:00.000Z'}`\n",
    "\n",
    "The full set of required and optional input parameters are listed in the Cultivate API documentation.\n",
    "\n",
    "### Recieving Responses\n",
    "\n",
    "When a GET or POST request is successfully executed, you will receive a JSON formatted response which can be accessed as the response's `.json()` object.\n",
    "\n",
    "#### Paging\n",
    "\n",
    "All paginated endpoints will also include 2 pagination-related response headers: `X-Total-Page-Count` and `X-Total-Record-Count`. `X-Total-Page-Count` contains the total number of pages available for your request, while `X-Total-Record-Count` contains the total number of records that will be included across all of those pages.\n",
    "\n",
    "You can access these through the response's `headers` dictionary:\n",
    "\n",
    "```\n",
    "result = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if result.ok:\n",
    "    totalPages = int(resp.headers.get('X-Total-Page-Count',0))\n",
    "```\n",
    "\n",
    "By default, results are returned for the first page (page 0), updating the `params` dictionary to include `params['page'] = 1` would get the next page.\n",
    "\n",
    "## Primary API Endpoints\n",
    "\n",
    "### Retrieving Questions\n",
    "\n",
    "Individual Forecasting Problems (IFPs) are questions about future events that solvers forecast against, and can be retrieved from the `questions` API endpoint. Each IFP includes, among other fields, an `id` a `description`, a set of `answers`, and a collection of `metadata` as well as starting and ending dates. Questions can be retrieved using a GET request with optional parameters.  The `status` parameter (values: active, closed, all) describes whether an IFP is open for forecast submission.  The several date parameters `created_before`, `created_after`, `updated_before`, and `updated_after` limit the response based on when questions were updated or created. The `training_data` parameter is new to GF Challenge 2 and is used to retrieve IFPs that were part of the HFC program but are not in GF Challenge 2 and which are available for Solvers to train their methods.  (More below).  The `answers` are a list of mutually exclusive, and collectively exhaustive options describing possible IFP outcomes. Forecasts must specify probabilities for each possible outcome that sum to 1.0 (except for binary questions (e.g., yes/no) for which only one option is presented, with the other option being calculated as 1 - Option A).\n",
    "\n",
    "The `metadata` that is returned includes `Domain`, `Topic`, and location information. In GF Challenge 2 the metadata will only be populated as an IFP is closed.  (In the first GF Challenge this metadata was provided when an IFP was launched.)  This metadata is provided *post hoc* to allow Solvers to evaluate their techniques for identifying the region or subject of an IFP but does not figure into scoring in any way, as there are no Domain or Region prizes in GF Challenge 2.  Refer to the [GF Challenge 2 Rules document](NEEDS URL ONCE PUBLISHED) and the API documentation to ensure that you accurately retrieve and handle the relevant fields. \n",
    "\n",
    "Each IFP also includes a list of `clarifications`. This will be populated if there is additional guidance regarding the IFP issued. This can include situations where terms are further defined, or sources of resolution are changed. You should regularly check for updates to this field.\n",
    "\n",
    "### Retrieving Individual and Aggregate Human Forecasts\n",
    "\n",
    "As part of the Challenge, solvers will have access to forecasts made by a crowd of human forecasters. These forecasts will be made available in two forms: individual and aggregate.  The individual forecasts are made available through the `prediction_sets` API end point, while the aggregate forecasts are provided through the `consensus_histories` end point. The consensus is calculated using an aggregation algorithm called logit. The logit aggregation method is an extremizing method that uses a weighted geometric mean to aggregate forecasts. Forecaster weights are calculated based on 3 factors: historical accuracy, the frequency with which the forecaster updates his or her forecasts, and whether the forecaster completed a training course. The `consensus_histories` data also serve as the baseline against which Solvers will be compared. More details on the baseline and scoring can be found in the official GF Challenge 2 Rules.\n",
    "\n",
    "Individual forecasts contain the probability forecasts, including a `question_id` that maps to the `id` in from the `questions` endpoint and `membership_guid` which uniquely identifies the human forecaster. Each forecast will include a list of `predictions` reflecting the probabilities that person assigned to each possible answer. The `forecasted_probability` for each answer represents that person's beliefs for each answer.\n",
    "\n",
    "Consensus aggregations contain a `question_id` and `answer_id` pair that identify a particular answer option. The `normalized_value` for a particular answer reflects the score such that all answers to a particular question will sum to 1.0. This consensus is updated any time a human forecaster makes a new forecast against an IFP. The `consensus_histories` API end point contains a list of these updated consensus scores. The most recent consensus for a particular question reflects the current crowd consensus at that time. NOTE: With the exception of the first time you query this endpoint, you should NOT retrieve `consensus_histories` without specifying a `created_after` parameter.  \n",
    "\n",
    "### Training Data (New in GF Challenge 2)\n",
    "\n",
    "There are two collections of non-competition training data that are available for Solvers to train and backtest their methods.  The training data on the Staging platform includes IFPs, individual human forecasts, and consensus histories for 86 IFPs between December 2018 and March 2019.  All of these IFPs are closed and have been resolved.  The training data on the Production platform consists of these elements for HFC IFPs that launched before the start of the GF Challenge 2 competition and which are not included in the Challenge.  Depending on when you access the Production training data you may have a mixture of open and closed IFPs, especially early in the Challenge.\n",
    "\n",
    "Please note that `membership_guid` values for the Staging training data will not be reused in GF Challenge 2.  However the `membership_guid` values in the Production platform training data will map to the same forecasters during the competition and are suitable for determining forecaster attributes such as accuracy and update frequency.\n",
    "\n",
    "### Submitting Forecasts\n",
    "\n",
    "Forecast submission is done through an HTTP POST. Your forecast must include the `question_id`, an `external_predictor_attributes.method_name`, and `external_predictions_attributes`: a list of dictionaries each containing an `answer_id` and `value` for each of the forecast question's possible alternatives. The sum of the values must equal 1.0. \n",
    "\n",
    "Each Solver is allocated 40 methodological \"slots.\" These slots can be used to represent different strategies for weighting data sources, different algorithms, etc. The `method_name` parameter is used to identify which slot a forecast should be associated with. `method_name` can be up to 50 characters, and will be held constant throughout the challenge (i.e., you cannot add a 41st method). You will be scored on a per `method_name` basis, with only your best performing approach being considered for each prize category. For more details, review the GF Challenge 2 rules.\n",
    "\n",
    "A forecast submission can look like:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\"external_prediction_set\": {\n",
    "        \"question_id\": 123,\n",
    "        \"external_predictor_attributes\": {\n",
    "            \"method_name\": \"red\"\n",
    "            },\n",
    "        \"external_predictions_attributes\": [\n",
    "            {\"value\": 0.6, \"answer_id\": 431},\n",
    "            {\"value\": 0.35, \"answer_id\": 432},\n",
    "            {\"value\": 0.05, \"answer_id\": 433}\n",
    "            ]\n",
    "          }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful submission of a forecast to the submission endpoint will return a json summary of the submission, including the time of submission. A failure (e.g., incorrect `answer_id` or `value`s that don't total to 1.0, or attempting to create a 41st `method_name`) will result in json describing the error. It is advisable to inspect the resulting json to ensure it reflects the intended forecast.\n",
    "\n",
    "## Putting it All Together\n",
    "\n",
    "We can implement API access into a single Python class so we can make GET and POST requests in a consistent fashion.  Below, we define a `GfcApi` class that allows us to specify a server and API token one time and access all the API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from pprint import pprint #This is just to make things look pretty...\n",
    "\n",
    "#Make this python 2 and 3 compliant\n",
    "from __future__ import print_function\n",
    "\n",
    "class GfcApi(object):\n",
    "    \"\"\"\n",
    "        An example class for interacting with the Geopolitical Forecasting Challenge 2\n",
    "        API.  Note that this code is for reference purposes, no warranties are expressed\n",
    "        or implied.  \n",
    "    \"\"\"\n",
    "    def __init__(self,token,server,proxy=None,verbose=False):\n",
    "        \"\"\"\n",
    "            Create an instance of an API client. This assumes you have an OAuth token.\n",
    "            \n",
    "            Arguments\n",
    "            \n",
    "            REQUIRED\n",
    "            token - <string> - The secret API token assigned when registering on the \n",
    "                               Cultivate platform\n",
    "            \n",
    "            server - <string> - The beginning of the server url in the form:\n",
    "                                https://api.XXXXXXX.com.  This is described in the\n",
    "                                Cultivate API documentation\n",
    "            \n",
    "            OPTIONAL\n",
    "            proxy - <dictionary> - If you are behind a proxy server, you can specify the details\n",
    "                                   in the form: \n",
    "                                       proxy = {'http': http_proxy,\n",
    "                                                'https': https_proxy,\n",
    "                                                'ftp': ftp_proxy}\n",
    "                                   where an individual entry might be [ip address:port]. See the\n",
    "                                   requests library documentation for more details.\n",
    "                Default: None\n",
    "                \n",
    "            verbose - <boolean> - If true, we print GET and POST request URLs and params\n",
    "                Default: False\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.token = token\n",
    "        self.server = server\n",
    "        self.proxy = proxy\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.sess = requests.session()\n",
    "        self.rate_limit_delay = 1 #seconds between subsequent API calls\n",
    "        self.last_call_time = 0.0 \n",
    "        self.set_urls()\n",
    "    \n",
    "    def set_urls(self):\n",
    "        if not self.server.endswith('/'):\n",
    "            self.server += '/'\n",
    "    \n",
    "        self.api_base = self.server + 'api/v1/'\n",
    "    \n",
    "        self.consensus_histories_url = self.server + 'aggregation/api/v1/control/consensus_histories'\n",
    "        self.external_prediction_sets_url = self.api_base + 'external_prediction_sets'\n",
    "        self.prediction_sets_url = self.api_base + 'control/prediction_sets'\n",
    "        self.questions_url = self.api_base + 'questions'\n",
    "\n",
    "    def get_questions(self, status=None, created_before=None, created_after=None,\n",
    "                      sort='published_at', updated_before=None, updated_after=None,\n",
    "                      training_data=False):\n",
    "        \"\"\"\n",
    "            This function retrieves Individual Forecasting Problems (IFPs).\n",
    "\n",
    "            Optional Inputs:\n",
    "            status - <string> - IFP status\n",
    "                    Possible Values:\n",
    "                        'active' - only return questions that are currently open for forecasting\n",
    "                        'closed' - return all resolved or otherwised closed questions\n",
    "                        'all'    - return all active and closed questions\n",
    "                    Default Value:\n",
    "                        'active'\n",
    "\n",
    "            created_before - <datetime> - returns only questions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only questions created after this time\n",
    "            \n",
    "            sort - <string> - Sort order of returned questions\n",
    "                    Possible Values:\n",
    "                        'published_at'\n",
    "                        'ends_at'\n",
    "                        'resolved_at'\n",
    "                        'prediction_sets_count'\n",
    "                    Default Value:\n",
    "                        'published_at'\n",
    "            \n",
    "            updated_before - <datetime> - returns only questions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only questions updated after this time\n",
    "            \n",
    "            training_data - <boolean> - returns only the questions for the training data, \n",
    "                otherwise returns competition questions.  Default False.\n",
    "                    \n",
    "             Output:\n",
    "            JSON representation of a list of Individual Forecasting Problems\n",
    "        \"\"\"\n",
    "        \n",
    "        url = self.questions_url\n",
    "        section = 'questions'\n",
    "        params={}\n",
    "        \n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if created_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if created_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        if status:\n",
    "            params['status'] = status\n",
    "        if sort:\n",
    "            params['sort'] = sort\n",
    "        if training_data:\n",
    "            params['training_data'] = 'true'\n",
    "        \n",
    "        return self._get_pages(url=url,section=section,params=params)\n",
    "    \n",
    "    def get_human_forecasts(self, question_id=None, created_before=None, created_after=None,\n",
    "                           updated_before=None, updated_after=None, training_data=False):\n",
    "\n",
    "        \"\"\"\n",
    "            This function retrieves the stream of human forecasts against IFPs.\n",
    "\n",
    "            Optional Inputs:\n",
    "            question_id - <integer> - returns predictions for a single question\n",
    "                    Default Value:\n",
    "                        None\n",
    "\n",
    "            created_before - <datetime> - returns only predictions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only predictions created after this time\n",
    "            \n",
    "            updated_before - <datetime> - returns only predictions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only predictions updated after this time\n",
    "\n",
    "            training_data - <boolean> - returns only the human forecasts for the training data, \n",
    "                    otherwise returns competition human forecasts.  Default is False.\n",
    "                                        \n",
    "             Output:\n",
    "            JSON representation of a list of human forecasts\n",
    "        \"\"\"\n",
    "        \n",
    "        url = self.prediction_sets_url\n",
    "        section = 'prediction_sets'\n",
    "        params={}\n",
    "        \n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if updated_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if updated_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        if question_id:\n",
    "            params['question_id'] = question_id\n",
    "        if training_data:\n",
    "            params['training_data'] = \"true\"\n",
    "\n",
    "       \n",
    "        return self._get_pages(url=url,section=section,params=params)        \n",
    "    \n",
    "    def get_consensus_histories(self, question_id=None, created_before=None, created_after=None,\n",
    "                           updated_before=None, updated_after=None, training_data=False):\n",
    "\n",
    "        \"\"\"\n",
    "            This function retrieves the consensus of human forecasts against IFPs.\n",
    "\n",
    "            NOTE: You need to include some date constraints after your first use of this API. \n",
    "            Always utilize the created_after parameter to pull only those records that have \n",
    "            been created since you last accessed the API. Do not attempt to pull every \n",
    "            record/page of the history.\n",
    "\n",
    "            Optional Inputs:\n",
    "            \n",
    "            question_id - <integer> - returns only predictions made about a specific IFP\n",
    "                Default Value\n",
    "                    None\n",
    "\n",
    "            created_before - <datetime> - returns only predictions created before this time\n",
    "\n",
    "            created_after - <datetime> - returns only predictions created after this time\n",
    "            \n",
    "            updated_before - <datetime> - returns only predictions updated before this time\n",
    "            \n",
    "            updated_after - <datetime> - returns only predictions updated after this time\n",
    "                    \n",
    "            training_data - <boolean> - returns only the consensus histories for the training data, \n",
    "                 otherwise returns competition consensus histories.  \n",
    "                 Default False.\n",
    "                    \n",
    "             Output:\n",
    "            JSON representation of a list of human forecasts\n",
    "        \"\"\"\n",
    "        \n",
    "        if (not created_before) and (not created_after) and (not updated_before) and (not updated_after):\n",
    "            print(\"After your first query, use a date constraint (created_before/after or\",\\\n",
    "                  \"updated_before/after) to get consensus history. Old values won't change\")\n",
    "        \n",
    "        url = self.consensus_histories_url\n",
    "        section = 'consensus_histories'\n",
    "        params={}\n",
    "        \n",
    "        if question_id:\n",
    "            params['question_id'] = str(question_id)\n",
    "        if created_before:\n",
    "            params['created_before'] = created_before.isoformat()\n",
    "        if created_after:\n",
    "            params['created_after'] = created_after.isoformat()\n",
    "        if updated_before:\n",
    "            params['updated_before'] = updated_before.isoformat()\n",
    "        if updated_after:\n",
    "            params['updated_after'] = updated_after.isoformat()\n",
    "        if training_data:\n",
    "            params['training_data'] = \"true\"\n",
    "\n",
    "        \n",
    "        return self._get_pages(url=url,section=section,params=params)   \n",
    "    \n",
    "    def submit_forecast(self,question_id,method_name,predictions):\n",
    "        \"\"\"\n",
    "            Submit probabilistic forecasts against a question.\n",
    "            \n",
    "            Required Parameters\n",
    "            \n",
    "            question_id - <integer> - The question_id of the IFP being forecast against\n",
    "            \n",
    "            method_name - <string> - The name of one of your 25 forecasting methods. Up to 50 chars\n",
    "                             NOTE: This is used to track and score your forecasting methods. You\n",
    "                             are responsible for keeping track of your named methods. Using a new\n",
    "                             method_name will automatically add a new method - unless you have\n",
    "                             already created 25 methods. In that case, you'll get an error message\n",
    "                             in the response.\n",
    "                             \n",
    "            predictions - <list> - A list of Dictionaries in the form .\n",
    "                                                   {'answer_id': <Integer>, 'value': <Decimal>}\n",
    "                            \n",
    "                          If the question is binary (exactly two possible answers), you only submit a\n",
    "                          prediction for one possible answer, with the other being equal to 1 minus\n",
    "                          your prediction for option A.\n",
    "                          \n",
    "                          NOTE: The set of values in the forecast must equal exactly 1.0 or you will \n",
    "                          receive an error message in the response.\n",
    "            \n",
    "     RESPONSE\n",
    "     The json response will either summarize your forecast to this question, or it will contain an \n",
    "     error message indicating why it wasn't accepted.  You are responsible for recieving and reviewing\n",
    "     the response to ensure that your forecast was accepted, and reflects your intentions.  You can \n",
    "     resubmit forecasts to a particular IFP repeatedly over the course of a forecast day, and each\n",
    "     new submission will replace older submissions for scoring purposes. Review the GF Challenge\n",
    "     Rules for details on forecast submission and scoring.\n",
    "        \"\"\"\n",
    "    \n",
    "        url = self.external_prediction_sets_url\n",
    "        \n",
    "        params={'external_prediction_set':{'question_id':question_id,\n",
    "                                          'external_predictor_attributes':\n",
    "                                           {'method_name':method_name},\n",
    "                                           'external_predictions_attributes':predictions}\n",
    "                }\n",
    "        \n",
    "        return self._post(url,params)\n",
    "    \n",
    "    def _forecast_template(self,ifp):\n",
    "        \"\"\"\n",
    "            A tiny little helper function to create the basis for the predictions parameter in\n",
    "            the submit_forecast function.  You pass an IFP from the questions API into this \n",
    "            function and receive a list of 'answer_id' and 'value' dictionaries that are\n",
    "            needed to submit a forecast.  \n",
    "            \n",
    "            NOTE: This sets the forecast probability (value field) to None, which will result in an error upon\n",
    "            submission.  You must set this to a legal probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        output = [{'answer_id':a['id'],'value':None} for a in ifp['answers']]\n",
    "        return output\n",
    "    \n",
    "    def _get_pages(self,url,params,section):\n",
    "        \n",
    "        \"\"\"\n",
    "            This function uses _get to make authenticated calls to the\n",
    "            relevant API endpoints with the user-provided parameters.\n",
    "            \n",
    "            This function handles paging through results, and returns only the list from\n",
    "            the resulting json result(s).\n",
    "            \n",
    "            The 'url' and 'params' describe the API query, the 'section' is the key in the\n",
    "            returned json that contains the list of query results (e.g., 'questions').\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print('Get Pages for {}'.format(url))\n",
    "            print(params)\n",
    "        page = 0\n",
    "        maxPage = 1\n",
    "        \n",
    "        all_results = []\n",
    "        this_batch = []\n",
    "        while page < maxPage: \n",
    "            \n",
    "            params['page']=page\n",
    "            resp = self._get(url=url,params=params)\n",
    "            maxPage = int(resp.headers.get('X-Total-Page-Count',0))\n",
    "            try:\n",
    "                results=resp.json()\n",
    "            except:\n",
    "                results=None\n",
    "            if isinstance(results,(list,dict)):\n",
    "                if 'errors' in results:\n",
    "                    print(results['errors'])\n",
    "                    return results\n",
    "                \n",
    "                this_batch = results[section]\n",
    "                all_results.extend(this_batch)\n",
    "\n",
    "                page+=1\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"PROBLEM\")\n",
    "                return results\n",
    "\n",
    "        return all_results                \n",
    "        \n",
    "    def _get(self,url,params):\n",
    "        \"\"\"\n",
    "            A helper function that handles authentication and rate limiting.\n",
    "            \n",
    "            Given a URL and a set of parameters, this function calls the Cultivate API\n",
    "            and returns the json response.\n",
    "        \"\"\"\n",
    "        \n",
    "        while time.time() < self.last_call_time + self.rate_limit_delay:\n",
    "            if self.verbose:\n",
    "                print(\"{}: Sleeping\".format(time.ctime()))\n",
    "            time.sleep(1)\n",
    "        \n",
    "        headers={'Authorization':'Bearer ' + self.token} #This is needed to authenticate\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"{}: GETTING {}\".format(time.ctime(),url))\n",
    "            safeHeaders = {k:v for k,v in headers.items() if k!='Authorization'}\n",
    "            safeHeaders['Authorization']=\"Bearer <shhhhhh it's a secret>\"\n",
    "            print(\"\\tHeaders: {}\".format(safeHeaders))\n",
    "            print(\"\\tArgs: {}\".format(params))\n",
    "        resp = self.sess.get(url, headers=headers, params=params, proxies=self.proxy)\n",
    "                                                                                         \n",
    "        self.last_call_time = time.time()\n",
    "        return resp\n",
    "    \n",
    "    def _post(self,url,params):\n",
    "        \"\"\"\n",
    "            A helper function that handles authentication.\n",
    "            \n",
    "            Given a URL and a set of parameters, this function submits a POST to the \n",
    "            Cultivate API and returns the json response.\n",
    "            \n",
    "            Output\n",
    "            JSON response describing the forecast or indicating an error.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        while time.time() < self.last_call_time + self.rate_limit_delay:\n",
    "            if self.verbose:\n",
    "                print(\"{}: Sleeping\".format(time.ctime()))\n",
    "            time.sleep(1)\n",
    "        \n",
    "        headers={'Authorization':'Bearer ' + self.token} #This is needed to authenticate\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"{}: POSTING {}\".format(time.ctime(),url))\n",
    "            safeHeaders = {k:v for k,v in headers.items() if k!='Authorization'}\n",
    "            safeHeaders['Authorization']=\"Bearer <shhhhhh it's a secret>\"\n",
    "            print(\"\\tHeaders: {}\".format(safeHeaders))\n",
    "            print(\"\\tArgs: {}\".format(params))\n",
    "        resp = self.sess.post(url, headers=headers, json=params, proxies=self.proxy) \n",
    "                                                                                         \n",
    "        self.last_call_time = time.time()\n",
    "        \n",
    "        return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can invoke this class by specifying our secret_token and server.\n",
    "\n",
    "One strategy for token management is to create a dictionary of server instances with the server address and API token like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your tokens in place of <STAGING API KEY> and <PRODUCTION API KEY> below.\n",
    "secrets = {'staging':\n",
    "              {'key':'<STAGING API KEY>',\n",
    "               'server':'https://api.gfc-staging.com'},\n",
    "           'production': \n",
    "              {'key':'<PRODUCTION API KEY>',\n",
    "               'server':'https://api.iarpagfchallenge.com'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an instance of the `GfcApi` class thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance='staging'\n",
    "gf=GfcApi(secrets[instance]['key'],secrets[instance]['server'],verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we create an instance of the `GfcApi` class, we retrieve Individual Forecasting Problems (IFPs). We could limit our queries of IFPs based on several criteria:\n",
    "\n",
    "- Question status (active or not)\n",
    "- Date of creation or update (useful for finding clarifications)\n",
    "- Training data (true or false)\n",
    "\n",
    "The code snippet below illustrates using an instance of the GfcApi class to retrieve IFPs from the staging platform and to summarize them by extracting some of the fields from the IFP content.  In this example no filters were applied for `status`, creation or update dates, or `training_data`, so the query retrieves all non-training data IFPs on the platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've downloaded 5 IFPs\n",
      "\n",
      "IFP 3010: Will Mexico file a trade dispute against any country with the WTO between 13 December 2019 and 22 January 2020?\n",
      "Description: \n",
      "Starts: 2019-03-25T01:54:09.000Z, Ends: 2020-01-23T02:54:09.000Z\n",
      "Options:\n",
      " (8192) Yes\n",
      "\n",
      "IFP 3009: Will any human walk on the moon before the end of 2021?\n",
      "Description: \n",
      "Starts: 2019-03-25T01:52:12.000Z, Ends: 2020-01-01T02:00:12.000Z\n",
      "Options:\n",
      " (8191) Yes\n",
      "\n",
      "IFP 3008: How many earthquakes of magnitude 5 or stronger will occur worldwide in January 2020?\n",
      "Description: \n",
      "Starts: 2019-03-25T01:50:19.000Z, Ends: 2020-02-01T02:00:19.000Z\n",
      "Options:\n",
      " (8190) Less than 103\n",
      " (8189) Between 103 and 142, inclusive\n",
      " (8188) More than 142 but less than 176\n",
      " (8187) Between 176 and 214, inclusive\n",
      " (8186) More than 214\n",
      "\n",
      "IFP 3007: What will be the daily closing spot price of Brent crude oil (USD per barrel) on 20 December 2019, according to the U.S. EIA?\n",
      "Description: \n",
      "Starts: 2019-03-25T01:47:03.000Z, Ends: 2019-12-20T23:00:03.000Z\n",
      "Options:\n",
      " (8185) Less than $57.70\n",
      " (8184) Between $57.70 and $59.64, inclusive\n",
      " (8183) More than $59.64 and less than $63.04\n",
      " (8182) Between $63.04 and $66.98, inclusive\n",
      " (8181) More than $66.98\n",
      "\n",
      "IFP 3006: What will the monthly percent change in the consumer price index (CPI) be for Estonia in August 2019?\n",
      "Description: \n",
      "Starts: 2019-03-25T01:43:13.000Z, Ends: 2019-09-02T01:43:13.000Z\n",
      "Options:\n",
      " (8180) Less than -38%\n",
      " (8179) Between -38% and -14%, inclusive\n",
      " (8178) Greater than -14% but less than 6%\n",
      " (8177) Between 6% and 30%, inclusive\n",
      " (8176) Greater than 30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifps=gf.get_questions()\n",
    "print(\"We've downloaded {} IFPs\\n\".format(len(ifps)))\n",
    "\n",
    "for ifp in ifps:\n",
    "    print(\"IFP {}: {}\".format(ifp['id'],ifp['name']))\n",
    "    print(\"Description: {}\".format(ifp['description']))\n",
    "    print(\"Starts: {}, Ends: {}\".format(ifp['starts_at'],ifp['ends_at']))\n",
    "    print(\"Options:\")\n",
    "    for answer in ifp['answers']:\n",
    "        print(' ({}) {}'.format(answer['id'],answer['name']))\n",
    "        \n",
    "    if ifp['clarifications']:\n",
    "        print('Clarifications:')\n",
    "        print(ifp['clarifications'])\n",
    "    print(\"\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve human forecasts. If we'd like, we can limit them to a particular `question_id`, and can constrain the creation or update dates. In this notebook we will set the `training_data` flag to `True` to ensure that there are human forecasts to retrieve from the staging platform.  To limit the response we will only look at the last portion of the training data by passing a value for `created_after`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 250 human forecasts\n"
     ]
    }
   ],
   "source": [
    "preds=gf.get_human_forecasts(training_data=True, created_after=datetime.datetime(2019,3,12,0,0,0))\n",
    "if 'errors' in preds:\n",
    "    print(\"We ran into a problem:\")\n",
    "    print(preds)\n",
    "else:\n",
    "    print(\"Retrieved {} human forecasts\".format(len(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an item in the human forecast stream. The `question_id` links us to the `get_questions()` results. The `membership_guid` is the unique identifier for a human forecaster, and will remain consistent throughout the Challenge.\n",
    "\n",
    "Each item in the `predictions` list includes the `answer_id` for that alternative, which aligns to the `get_questions()` output, and a `forecasted_probability` which indicates the human forecaster's submitted probability for that alternative.\n",
    "\n",
    "Here is an example prediction from the training data available on the staging platform.  Examining the elements of the forecast:\n",
    "\n",
    "- `created_at`: the timestamp of the forecast.\n",
    "- `id`: a unique identifier for the forecast.\n",
    "- `membership_guid`: a unique identifier for the forecaster.\n",
    "- `predictions`:  The IFP has 5 answers and the forecast includes probabilistic forecasts for all of the answers (multinomial or ordinal IFPs) or for the \"Yes\" answer (binary IFPs), found in the `forecasted_probability` field.  These forecasts add up to 1.0 (values are 0, 0, 0.5, 0.5, 0) for multinomial or ordinal IFPs.  For binary IFPs the forecast will be between 0 and 1.0 inclusive and the implicit forecast for the \"No\" answer is 1 - the forecast.\n",
    "- `question_id`: A unique identifier for the IFP.\n",
    "- `question_name`: The name of the IFP.\n",
    "- `rationale`: Forecaster entered text, explaining the reasoning behind the forecast.\n",
    "- `updated_at`: The timestamp the forecast was updated, generally the same as the `created_at` timestamp.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'created_at': '2019-03-12T18:00:03.675Z',\n",
    " 'id': 64797,\n",
    " 'membership_guid': '4662cf7dbb06d39017571d84ea88d6f1d69100a8',\n",
    " 'predictions': [{'answer_id': 8161,\n",
    "                  'answer_name': 'Less than $1,240',\n",
    "                  'final_probability': 0.0,\n",
    "                  'forecasted_probability': 0.0,\n",
    "                  'id': 154343,\n",
    "                  'made_after_correctness_known': False,\n",
    "                  'starting_probability': 0.0},\n",
    "                 {'answer_id': 8162,\n",
    "                  'answer_name': 'More than $1,240 but less than $1,290, '\n",
    "                                 'inclusive',\n",
    "                  'final_probability': 0.2,\n",
    "                  'forecasted_probability': 0.5,\n",
    "                  'id': 154344,\n",
    "                  'made_after_correctness_known': False,\n",
    "                  'starting_probability': 0.2},\n",
    "                 {'answer_id': 8163,\n",
    "                  'answer_name': 'Between $1,290 and $1,330',\n",
    "                  'final_probability': 0.55,\n",
    "                  'forecasted_probability': 0.5,\n",
    "                  'id': 154345,\n",
    "                  'made_after_correctness_known': False,\n",
    "                  'starting_probability': 0.55},\n",
    "                 {'answer_id': 8164,\n",
    "                  'answer_name': 'More than $1,330 but less than $1,380, '\n",
    "                                 'inclusive',\n",
    "                  'final_probability': 0.1,\n",
    "                  'forecasted_probability': 0.0,\n",
    "                  'id': 154346,\n",
    "                  'made_after_correctness_known': False,\n",
    "                  'starting_probability': 0.1},\n",
    "                 {'answer_id': 8165,\n",
    "                  'answer_name': 'More than $1,380',\n",
    "                  'final_probability': 0.0,\n",
    "                  'forecasted_probability': 0.0,\n",
    "                  'id': 154347,\n",
    "                  'made_after_correctness_known': False,\n",
    "                  'starting_probability': 0.0}],\n",
    " 'question_id': 2995,\n",
    " 'question_name': 'What will be the daily closing price of gold on 13 March '\n",
    "                  '2019 in USD?',\n",
    " 'rationale': 'This is really down to the last minute. The price has been '\n",
    "              'teetering just around the 1290 mark for several days. It will '\n",
    "              'either be slightly above or slightly below 1290 by tomorrow, '\n",
    "              'which is the end of the time period.',\n",
    " 'updated_at': '2019-03-12T18:00:03.675Z'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the baseline consensus forecasts using `get_consensus_histories()`. As described in the API documentation, and above, after your first call to this API endpoint, you should constrain your requests using something like `created_after` while storing and tracking older values locally. Note that we're using `datetime.datetime()` objects to specify the `created` and `updated` parameters. You can limit this request by `question_id` if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved 325 consensus scores\n"
     ]
    }
   ],
   "source": [
    "cons = gf.get_consensus_histories(created_after=datetime.datetime(2019,3,12,0,0,0),\n",
    "                                  updated_before=datetime.datetime(2019,3,14),\n",
    "                                  training_data=True) \n",
    "print(\"retrieved {} consensus scores\".format(len(cons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these results. Note that each item in the list represents a single answer -- unlike an item in the `get_human_forecasts()` results where each entry represents the predictions for each possible answer for a single IFP.\n",
    "\n",
    "The `normalized_value` scores for all the answers to a single IFP for a specific `consensus_at` time will add up to 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example consensus history from the training data on the staging platform.\n",
    "\n",
    "- `answer_id`: Identifier for the answer, matches the questions API.\n",
    "- `consensus_at`, `created_at`, `updated_at`: Timestamp for the consensus creation, computation, and update.  Typically the same or very close in time.\n",
    "- `decay_args`, `decay_method`, `strategy`, `weighting_settings`, `method_name`: \"Under the hood\" parameters for the method of aggregating individual forecasts to produce the consensus.  Solvers can ignore these.\n",
    "- `id`: The identifier for this consensus history.\n",
    "- `normalized_value`: **The baseline method forecast**, The consensus forecast value for this answer.\n",
    "- `prediction_set_id`:  Collective identifier for the answer consensus elements corresponding to the consensus for an IFP.\n",
    "- `question_id`: The identifier for the IFP\n",
    "- `value`: The raw output from the aggregator, **not to be used as a probability value**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'answer_id': 7015,\n",
    " 'consensus_at': '2019-03-13T14:28:40.843Z',\n",
    " 'created_at': '2019-03-13T14:28:41.951Z',\n",
    " 'decay_args': {'percent': 0.468},\n",
    " 'decay_method': 'Aggregation::Decay::PercentRecent',\n",
    " 'id': 107249,\n",
    " 'method_name': '1-WeightedLogit-PercentRecent',\n",
    " 'normalized_value': 0.00166729,\n",
    " 'prediction_set_id': 64780,\n",
    " 'question_id': 2595,\n",
    " 'strategy': 'Aggregation::Strategies::Logit',\n",
    " 'updated_at': '2019-03-13T14:28:41.951Z',\n",
    " 'value': 0.013881,\n",
    " 'weighting_settings': {'count_of_closed_questions_answered_requirement': 35,\n",
    "                        'enabled': True,\n",
    "                        'minimum_closed_questions_to_enable_accuracy_weighting': 10,\n",
    "                        'percentage_of_closed_questions_answered_requirement': 0.5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and submitting a forecast\n",
    "---\n",
    "\n",
    "The `submit_forecast()` function is used to submit probabilistic forecasts against IFPs.  Each forecast must include the `question_id`, a `method_name`, and `predictions`, a list of question_id and value dictionaries that reflect your beliefs about how the IFP will resolve. The sum of all the values must equal 1.0, unless the IFP is a binary question (having only two possible outcomes), in which case, only the forecast for Option A is submitted, with Option B being inferred to be 1 minus the value of Option A.\n",
    "\n",
    "We can make this process a bit easier by taking advantage of the `_forecast_template()` function to create a starting list of forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting IFP 3008, using the \"Roll a d20\" method:\n",
      "[{'answer_id': 8190, 'value': 0.5},\n",
      " {'answer_id': 8189, 'value': 0.1},\n",
      " {'answer_id': 8188, 'value': 0.1},\n",
      " {'answer_id': 8187, 'value': 0.05},\n",
      " {'answer_id': 8186, 'value': 0.25}]\n",
      "Forecast probabilities sum to 1.0\n",
      "\n",
      "\n",
      "{'created_at': '2019-04-03T18:33:30.918Z',\n",
      " 'discover_question_id': 3,\n",
      " 'external_predictions': [{'answer_id': 8190,\n",
      "                           'created_at': '2019-04-03T18:33:30.935Z',\n",
      "                           'discover_answer_id': 11,\n",
      "                           'forecast_at': '2019-04-03T18:33:30Z',\n",
      "                           'id': 122940,\n",
      "                           'membership_id': 368,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 3008,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2019-04-03T18:33:30.935Z',\n",
      "                           'value': 0.5},\n",
      "                          {'answer_id': 8189,\n",
      "                           'created_at': '2019-04-03T18:33:30.939Z',\n",
      "                           'discover_answer_id': 12,\n",
      "                           'forecast_at': '2019-04-03T18:33:30Z',\n",
      "                           'id': 122941,\n",
      "                           'membership_id': 368,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 3008,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2019-04-03T18:33:30.939Z',\n",
      "                           'value': 0.1},\n",
      "                          {'answer_id': 8188,\n",
      "                           'created_at': '2019-04-03T18:33:30.941Z',\n",
      "                           'discover_answer_id': 13,\n",
      "                           'forecast_at': '2019-04-03T18:33:30Z',\n",
      "                           'id': 122942,\n",
      "                           'membership_id': 368,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 3008,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2019-04-03T18:33:30.941Z',\n",
      "                           'value': 0.1},\n",
      "                          {'answer_id': 8187,\n",
      "                           'created_at': '2019-04-03T18:33:30.944Z',\n",
      "                           'discover_answer_id': 14,\n",
      "                           'forecast_at': '2019-04-03T18:33:30Z',\n",
      "                           'id': 122943,\n",
      "                           'membership_id': 368,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 3008,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2019-04-03T18:33:30.944Z',\n",
      "                           'value': 0.05},\n",
      "                          {'answer_id': 8186,\n",
      "                           'created_at': '2019-04-03T18:33:30.948Z',\n",
      "                           'discover_answer_id': 15,\n",
      "                           'forecast_at': '2019-04-03T18:33:30Z',\n",
      "                           'id': 122944,\n",
      "                           'membership_id': 368,\n",
      "                           'method_name': 'Roll a d20',\n",
      "                           'question_id': 3008,\n",
      "                           'site_id': 2,\n",
      "                           'updated_at': '2019-04-03T18:33:30.948Z',\n",
      "                           'value': 0.25}],\n",
      " 'forecast_at': '2019-04-03T18:33:30Z',\n",
      " 'id': 50133,\n",
      " 'membership_id': 368,\n",
      " 'metadata': None,\n",
      " 'method_name': 'Roll a d20',\n",
      " 'method_type': 'official',\n",
      " 'question_id': 3008,\n",
      " 'site_id': 2,\n",
      " 'updated_at': '2019-04-03T18:33:30.918Z'}\n"
     ]
    }
   ],
   "source": [
    "myIFP = ifps[2]\n",
    "id=myIFP['id']\n",
    "\n",
    "method=\"Roll a d20\"\n",
    "\n",
    "forecasts = gf._forecast_template(myIFP)\n",
    "\n",
    "forecasts[0]['value'] = 0.5  #Set our probability for this option\n",
    "forecasts[1]['value'] = 0.1\n",
    "forecasts[2]['value'] = .1\n",
    "forecasts[3]['value'] = .05\n",
    "forecasts[4]['value'] = .25\n",
    "\n",
    "print('Forecasting IFP {}, using the \"{}\" method:'.format(id,method))\n",
    "pprint(forecasts)\n",
    "forecast_sum = sum(f[\"value\"] for f in forecasts)\n",
    "print(\"Forecast probabilities sum to {}\".format(forecast_sum))\n",
    "\n",
    "result = gf.submit_forecast(id,method,forecasts)\n",
    "print(\"\\n\")\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what happens when your answers sum to something other than 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting IFP 3008, using the \"Roll a d20\" method:\n",
      "[{'answer_id': 8190, 'value': 0.6},\n",
      " {'answer_id': 8189, 'value': 0.1},\n",
      " {'answer_id': 8188, 'value': 0.1},\n",
      " {'answer_id': 8187, 'value': 0.05},\n",
      " {'answer_id': 8186, 'value': 0.25}]\n",
      "Forecast probabilities sum to 1.1\n",
      "\n",
      "\n",
      "{'errors': {'predictions': ['must add up to 100%']}}\n"
     ]
    }
   ],
   "source": [
    "myIFP = ifps[2]\n",
    "id=myIFP['id']\n",
    "\n",
    "method=\"Roll a d20\"\n",
    "\n",
    "forecasts = gf._forecast_template(myIFP)\n",
    "\n",
    "forecasts[0]['value'] = 0.6  #This is different than the previous entry, and will push our total to 1.1\n",
    "forecasts[1]['value'] = 0.1\n",
    "forecasts[2]['value'] = .4\n",
    "forecasts[2]['value'] = .1\n",
    "forecasts[3]['value'] = .05\n",
    "forecasts[4]['value'] = .25\n",
    "\n",
    "print('Forecasting IFP {}, using the \"{}\" method:'.format(id,method))\n",
    "pprint(forecasts)\n",
    "forecast_sum = sum(f[\"value\"] for f in forecasts)\n",
    "print(\"Forecast probabilities sum to {}\".format(forecast_sum))\n",
    "\n",
    "result = gf.submit_forecast(id,method,forecasts)\n",
    "print(\"\\n\")\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what happens when one of your forecast probabilities is not a legal probability value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting IFP 3008, using the \"Roll a d20\" method:\n",
      "[{'answer_id': 8190, 'value': 0.5},\n",
      " {'answer_id': 8189, 'value': 0.1},\n",
      " {'answer_id': 8188, 'value': -0.1},\n",
      " {'answer_id': 8187, 'value': 0.25},\n",
      " {'answer_id': 8186, 'value': 0.25}]\n",
      "Forecast probabilities sum to 1.0\n",
      "\n",
      "\n",
      "{'errors': {'external_predictions.value': ['must be greater than or equal to '\n",
      "                                           '0']}}\n"
     ]
    }
   ],
   "source": [
    "myIFP = ifps[2]\n",
    "id=myIFP['id']\n",
    "\n",
    "method=\"Roll a d20\"\n",
    "\n",
    "forecasts = gf._forecast_template(myIFP)\n",
    "\n",
    "forecasts[0]['value'] = 0.5  \n",
    "forecasts[1]['value'] = 0.1\n",
    "forecasts[2]['value'] = 0.5\n",
    "forecasts[2]['value'] = -.1 # Not a legal probability\n",
    "forecasts[3]['value'] = .25\n",
    "forecasts[4]['value'] = .25\n",
    "\n",
    "print('Forecasting IFP {}, using the \"{}\" method:'.format(id,method))\n",
    "pprint(forecasts)\n",
    "forecast_sum = sum(f[\"value\"] for f in forecasts)\n",
    "print(\"Forecast probabilities sum to {}\".format(forecast_sum))\n",
    "\n",
    "result = gf.submit_forecast(id,method,forecasts)\n",
    "print(\"\\n\")\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Thoughts\n",
    "Your solution to the Challenge will need to interact, at the very least with the `questions` and `external_prediction_sets` end points. You will need to make authenticated calls to GET and POST to these end points. You may use any of the concepts or code in this document to help you accomplish these tasks, but please note that you are responsible for ensuring that you are correctly retrieving and submitting information to the API.\n",
    "\n",
    "Note that you should be on the lookout for errors that are returned either because of connectivity issues (Requests library) or as returned json content from the Cultivate API.  The examples in this document don't include comprehensive error checking or handling."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
